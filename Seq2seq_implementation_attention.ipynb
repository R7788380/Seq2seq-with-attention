{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "import helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = '../data/letters_source.txt'\n",
    "target_path = '../data/letters_target.txt'\n",
    "\n",
    "source_sentences = helper.load_data(source_path)\n",
    "target_sentences = helper.load_data(target_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bsaqq\n",
      "npy\n",
      "\n",
      "{0: '<PAD>', 1: '<UNK>', 2: '<GO>', 3: '<EOS>', 4: 'a', 5: 'b', 6: 'c', 7: 'd', 8: 'e', 9: 'f', 10: 'g', 11: 'h', 12: 'i', 13: 'j', 14: 'k', 15: 'l', 16: 'm', 17: 'n', 18: 'o', 19: 'p', 20: 'q', 21: 'r', 22: 's', 23: 't', 24: 'u', 25: 'v', 26: 'w', 27: 'x', 28: 'y', 29: 'z'}\n",
      "Example source sequence\n",
      "[[5, 22, 4, 20, 20], [17, 19, 28], [15, 5, 26, 24, 13]]\n",
      "\n",
      "\n",
      "Example target sequence\n",
      "[[4, 5, 20, 20, 22, 3], [17, 19, 28, 3], [5, 13, 15, 24, 26, 3]]\n"
     ]
    }
   ],
   "source": [
    "def extract_character_vocab(data):\n",
    "    special_words = ['<PAD>', '<UNK>', '<GO>',  '<EOS>']\n",
    "\n",
    "    set_words = sorted(list(set([character for line in data.split('\\n') for character in line])))\n",
    "    int_to_vocab = {word_i: word for word_i, word in enumerate(special_words + set_words)}\n",
    "    vocab_to_int = {word: word_i for word_i, word in int_to_vocab.items()}\n",
    "\n",
    "    return int_to_vocab, vocab_to_int\n",
    "\n",
    "# Build int2letter and letter2int dicts\n",
    "source_int_to_letter, source_letter_to_int = extract_character_vocab(source_sentences)\n",
    "target_int_to_letter, target_letter_to_int = extract_character_vocab(target_sentences)\n",
    "print(source_sentences[:10])\n",
    "print(source_int_to_letter)\n",
    "# print(source_letter_to_int)\n",
    "# Convert characters to ids\n",
    "source_letter_ids = [[source_letter_to_int.get(letter, source_letter_to_int['<UNK>']) for letter in line] for line in source_sentences.split('\\n')]\n",
    "target_letter_ids = [[target_letter_to_int.get(letter, target_letter_to_int['<UNK>']) for letter in line] + [target_letter_to_int['<EOS>']] for line in target_sentences.split('\\n')] \n",
    "\n",
    "print(\"Example source sequence\")\n",
    "print(source_letter_ids[:3])\n",
    "print(\"\\n\")\n",
    "print(\"Example target sequence\")\n",
    "print(target_letter_ids[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.10.0\n"
     ]
    }
   ],
   "source": [
    "from distutils.version import LooseVersion\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.layers.core import Dense\n",
    "\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.1'), 'Please use TensorFlow version 1.1 or newer'\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2seq with attention mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class seq2seq_attention_model():\n",
    "    def __init__(self, \n",
    "                 source_letter_to_int, \n",
    "                 target_letter_to_int,\n",
    "                 batch_size,\n",
    "                 enc_embed_size,\n",
    "                 dec_embed_size,\n",
    "                 enc_rnn_size,\n",
    "                 dec_rnn_size,\n",
    "                 enc_num_layers,\n",
    "                 dec_num_layers,\n",
    "                 attention_units_size,\n",
    "                 learning_rate):\n",
    "        \n",
    "        self.source_letter_to_int = source_letter_to_int\n",
    "        self.target_letter_to_int = target_letter_to_int\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.enc_embed_size = enc_embed_size\n",
    "        self.dec_embed_size = dec_embed_size\n",
    "        self.enc_rnn_size = enc_rnn_size\n",
    "        self.dec_rnn_size = dec_rnn_size\n",
    "        self.enc_num_layers = enc_num_layers\n",
    "        self.dec_num_layers = dec_num_layers\n",
    "        self.attention_units_size = attention_units_size\n",
    "        self.learning_rate = learning_rate\n",
    "    \n",
    "    def encoder(self, sources, source_length):\n",
    "        enc_embed_input = tf.contrib.layers.embed_sequence(ids=sources, \n",
    "                                                           vocab_size=len(self.source_letter_to_int), \n",
    "                                                           embed_dim=self.enc_embed_size)\n",
    "\n",
    "        enc_cells = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.LSTMCell(self.enc_rnn_size, initializer=tf.random_uniform_initializer(-0.1,0.1,seed=2)) for _ in range(self.enc_num_layers)])\n",
    "    \n",
    "        enc_output, enc_state = tf.nn.dynamic_rnn(cell=enc_cells, \n",
    "                                                  inputs=enc_embed_input, \n",
    "                                                  sequence_length=source_length,\n",
    "                                                  dtype=tf.float32)\n",
    "        \n",
    "        return enc_output, enc_state\n",
    "    \n",
    "    def process_dec_input(self, targets):\n",
    "        ending = tf.strided_slice(targets, begin=[0,0], end=[self.batch_size,-1], strides=[1,1])\n",
    "        fill_value = tf.fill(dims=[self.batch_size,1], value=self.target_letter_to_int['<GO>'])\n",
    "        dec_input = tf.concat([fill_value, ending], axis=1)\n",
    "        return dec_input\n",
    "    \n",
    "    def decoder(self, dec_input, enc_output, enc_state, source_length, target_length, max_target_length, attention):\n",
    "        dec_embeddings = tf.Variable(tf.random_uniform([len(self.target_letter_to_int), self.dec_embed_size]))\n",
    "        dec_embed_input = tf.nn.embedding_lookup(params=dec_embeddings, ids=dec_input)\n",
    "        \n",
    "        dec_cells = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.LSTMCell(self.dec_rnn_size, initializer=tf.random_uniform_initializer(-0.1,0.1,seed=2)) for _ in range(self.dec_num_layers)])\n",
    "        \n",
    "        # Attention\n",
    "        \"\"\"\n",
    "        tensorflow實現的attention mechanism有兩種\n",
    "        1. Bahdanau (就是 Neural machine translation by jointly learning to align and translate 的作者)\n",
    "        attention的鼻祖，使用一層NN來學習attention weight\n",
    "        \n",
    "        2. Luong (Effective approaches to attention-based neural machine translation)\n",
    "        改良attention weight的產生方式，有dot, general以及concat三種\n",
    "        \"\"\"\n",
    "        if attention is 'Luong':\n",
    "            attention_mechanism = tf.contrib.seq2seq.LuongAttention(num_units=self.attention_units_size, \n",
    "                                                                    memory=enc_output, \n",
    "                                                                    memory_sequence_length=source_length)\n",
    "        else:\n",
    "            attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(num_units=self.attention_units_size,\n",
    "                                                                       memory=enc_output,\n",
    "                                                                       memory_sequence_length=source_length)\n",
    "        \n",
    "        attn_cell = tf.contrib.seq2seq.AttentionWrapper(cell=dec_cells,attention_layer_size=self.dec_rnn_size/2,\n",
    "                                                        attention_mechanism=attention_mechanism,\n",
    "                                                        alignment_history=True,\n",
    "                                                        output_attention=True)\n",
    "        \n",
    "        output_layer = tf.layers.Dense(len(self.target_letter_to_int), kernel_initializer=tf.truncated_normal_initializer(mean=0.0,stddev=0.1))\n",
    "        \n",
    "        initial_state = attn_cell.zero_state(batch_size=self.batch_size, dtype=tf.float32).clone(cell_state=enc_state)\n",
    "        \n",
    "        # Training\n",
    "        with tf.variable_scope('decoder'):\n",
    "\n",
    "            training_helper = tf.contrib.seq2seq.TrainingHelper(inputs=dec_embed_input, \n",
    "                                                                sequence_length=target_length)\n",
    "            training_decoder = tf.contrib.seq2seq.BasicDecoder(cell=attn_cell, \n",
    "                                                               helper=training_helper, \n",
    "                                                               initial_state=initial_state,\n",
    "                                                               output_layer=output_layer)\n",
    "            train_logits, train_final_state, train_final_sequence_lengths = tf.contrib.seq2seq.dynamic_decode(decoder=training_decoder)\n",
    "\n",
    "            self.train_attention_metrices = train_final_state.alignment_history.stack(name='training_attention_metrices')\n",
    "        \n",
    "        # Inference\n",
    "        with tf.variable_scope('decoder', reuse=True):\n",
    "            start_tokens = tf.tile(tf.constant([self.target_letter_to_int['<GO>']],dtype=tf.int32), [self.batch_size])\n",
    "            end_token = self.target_letter_to_int['<EOS>']\n",
    "            inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(embedding=dec_embeddings, \n",
    "                                                                        start_tokens=start_tokens, \n",
    "                                                                        end_token=end_token)\n",
    "            inference_decoder = tf.contrib.seq2seq.BasicDecoder(cell=attn_cell,\n",
    "                                                                helper=inference_helper,\n",
    "                                                                initial_state=initial_state,\n",
    "                                                                output_layer=output_layer)\n",
    "\n",
    "            inference_logits, inference_final_state, _ = tf.contrib.seq2seq.dynamic_decode(decoder=inference_decoder,\n",
    "                                                                                           output_time_major=False,\n",
    "                                                                                           impute_finished=True,\n",
    "                                                                                           maximum_iterations=max_target_length)\n",
    "            self.inference_attention_metrices = inference_final_state.alignment_history.stack(name='inference_attention_metrices')\n",
    "        \n",
    "        return train_logits, inference_logits\n",
    "    \n",
    "    def compute_loss(self, train_logits, inference_logits, target_length, max_target_length):\n",
    "        self.training_logits = tf.identity(train_logits.rnn_output, name='logits')\n",
    "        self.predict_logits = tf.identity(inference_logits.sample_id, name='predictions')\n",
    "        \n",
    "        masks = tf.sequence_mask(target_length, max_target_length, dtype=tf.float32, name='masks')\n",
    "        \n",
    "        self.loss = tf.contrib.seq2seq.sequence_loss(logits=self.training_logits, targets=targets, weights=masks)\n",
    "        \n",
    "        optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        \n",
    "        gradients = optimizer.compute_gradients(self.loss)\n",
    "        capped_gradients = [(tf.clip_by_value(grad, -5., 5.), var) for grad, var in gradients if grad is not None]\n",
    "        self.train_op = optimizer.apply_gradients(capped_gradients)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "\n",
    "enc_embed_size = 15\n",
    "dec_embed_size = 15\n",
    "\n",
    "enc_rnn_size = 50\n",
    "dec_rnn_size = 50\n",
    "\n",
    "enc_num_layers = 2\n",
    "dec_num_layers = 2\n",
    "\n",
    "attention_units_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "graph = tf.Graph()\n",
    "with graph.as_default(): \n",
    "    sources = tf.placeholder(shape=[None, None], dtype=tf.int32, name='sources')\n",
    "    targets = tf.placeholder(shape=[None, None], dtype=tf.int32, name='targets')\n",
    "        \n",
    "    source_length = tf.placeholder(shape=[None,], dtype=tf.int32, name='source_length')\n",
    "    target_length = tf.placeholder(shape=[None,], dtype=tf.int32, name='target_length')\n",
    "    max_target_length = tf.reduce_max(target_length, name='max_target_length')\n",
    "        \n",
    "    seq2seq_attn = seq2seq_attention_model(source_letter_to_int, \n",
    "                                           target_letter_to_int, \n",
    "                                           batch_size, \n",
    "                                           enc_embed_size,\n",
    "                                           dec_embed_size,\n",
    "                                           enc_rnn_size,\n",
    "                                           dec_rnn_size,\n",
    "                                           enc_num_layers,\n",
    "                                           dec_num_layers,\n",
    "                                           attention_units_size,\n",
    "                                           learning_rate)\n",
    "    enc_output, enc_state = seq2seq_attn.encoder(sources, source_length)\n",
    "    dec_input = seq2seq_attn.process_dec_input(targets)\n",
    "    train_logits, inference_logits = seq2seq_attn.decoder(dec_input, enc_output, enc_state, source_length, target_length, max_target_length, attention='Bahdanau')\n",
    "    seq2seq_attn.compute_loss(train_logits, inference_logits, target_length, max_target_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sentence_batch(sentence_batch, pad_int):\n",
    "    \"\"\"Pad sentences with <PAD> so that each sentence of a batch has the same length\"\"\"\n",
    "    max_sentence = max([len(sentence) for sentence in sentence_batch]) \n",
    "    return [sentence + [pad_int] * (max_sentence - len(sentence)) for sentence in sentence_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(targets, sources, batch_size, source_pad_int, target_pad_int):\n",
    "    \"\"\"Batch targets, sources, and the lengths of their sentences together\"\"\"\n",
    "    for batch_i in range(0, len(sources)//batch_size):\n",
    "        start_i = batch_i * batch_size\n",
    "        sources_batch = sources[start_i:start_i + batch_size]\n",
    "        targets_batch = targets[start_i:start_i + batch_size]\n",
    "        sources_pad_batch = np.array(pad_sentence_batch(sources_batch, source_pad_int))\n",
    "        targets_pad_batch = np.array(pad_sentence_batch(targets_batch, target_pad_int))\n",
    "        \n",
    "        # Need the lengths for the _lengths parameters\n",
    "        source_batch_length = [len(sequence) for sequence in sources_batch]\n",
    "        target_batch_length = [len(sequence) for sequence in targets_batch]\n",
    "        \n",
    "        yield sources_pad_batch, targets_pad_batch, source_batch_length, target_batch_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 train_loss: 3.0095, valid_loss: 2.5948\n",
      "2.492288112640381\n",
      "Epoch 2/100 train_loss: 2.2191, valid_loss: 1.9515\n",
      "1.667057991027832\n",
      "Epoch 3/100 train_loss: 1.8172, valid_loss: 1.6755\n",
      "1.663804292678833\n",
      "Epoch 4/100 train_loss: 1.5682, valid_loss: 1.4489\n",
      "1.6812083721160889\n",
      "Epoch 5/100 train_loss: 1.3193, valid_loss: 1.2593\n",
      "1.6800501346588135\n",
      "Epoch 6/100 train_loss: 1.1622, valid_loss: 1.1346\n",
      "1.680969476699829\n",
      "Epoch 7/100 train_loss: 1.0530, valid_loss: 1.0211\n",
      "1.662083387374878\n",
      "Epoch 8/100 train_loss: 0.9505, valid_loss: 0.9203\n",
      "1.6908199787139893\n",
      "Epoch 9/100 train_loss: 0.8493, valid_loss: 0.8187\n",
      "1.6761813163757324\n",
      "Epoch 10/100 train_loss: 0.7435, valid_loss: 0.7102\n",
      "1.6754069328308105\n",
      "Epoch 11/100 train_loss: 0.6041, valid_loss: 0.5389\n",
      "1.682664394378662\n",
      "Epoch 12/100 train_loss: 0.4067, valid_loss: 0.3005\n",
      "1.681976318359375\n",
      "Epoch 13/100 train_loss: 0.2125, valid_loss: 0.1643\n",
      "1.6579089164733887\n",
      "Epoch 14/100 train_loss: 0.1155, valid_loss: 0.0984\n",
      "1.6793882846832275\n",
      "Epoch 15/100 train_loss: 0.0759, valid_loss: 0.0694\n",
      "1.687669038772583\n",
      "Epoch 16/100 train_loss: 0.0628, valid_loss: 0.0438\n",
      "1.6575617790222168\n",
      "Epoch 17/100 train_loss: 0.0339, valid_loss: 0.0319\n",
      "1.6679184436798096\n",
      "Epoch 18/100 train_loss: 0.0239, valid_loss: 0.0263\n",
      "1.6776189804077148\n",
      "Epoch 19/100 train_loss: 0.0192, valid_loss: 0.0235\n",
      "1.6633660793304443\n",
      "Epoch 20/100 train_loss: 0.0207, valid_loss: 0.0252\n",
      "1.6883234977722168\n",
      "Epoch 21/100 train_loss: 0.0190, valid_loss: 0.0211\n",
      "1.644045352935791\n",
      "Epoch 22/100 train_loss: 0.0804, valid_loss: 0.0379\n",
      "1.6838369369506836\n",
      "Epoch 23/100 train_loss: 0.0147, valid_loss: 0.0152\n",
      "1.682769536972046\n",
      "Epoch 24/100 train_loss: 0.0090, valid_loss: 0.0119\n",
      "1.6689152717590332\n",
      "Epoch 25/100 train_loss: 0.0070, valid_loss: 0.0107\n",
      "1.6550767421722412\n",
      "Epoch 26/100 train_loss: 0.0058, valid_loss: 0.0099\n",
      "1.677048683166504\n",
      "Epoch 27/100 train_loss: 0.0050, valid_loss: 0.0093\n",
      "1.6764202117919922\n",
      "Epoch 28/100 train_loss: 0.0043, valid_loss: 0.0088\n",
      "1.6871106624603271\n",
      "Epoch 29/100 train_loss: 0.0038, valid_loss: 0.0082\n",
      "1.6819288730621338\n",
      "Epoch 30/100 train_loss: 0.0033, valid_loss: 0.0076\n",
      "1.6798367500305176\n",
      "Epoch 31/100 train_loss: 0.0029, valid_loss: 0.0071\n",
      "1.670154333114624\n",
      "Epoch 32/100 train_loss: 0.0026, valid_loss: 0.0066\n",
      "1.6604154109954834\n",
      "Epoch 33/100 train_loss: 0.0024, valid_loss: 0.0062\n",
      "1.674466848373413\n",
      "Epoch 34/100 train_loss: 0.0022, valid_loss: 0.0058\n",
      "1.6865625381469727\n",
      "Epoch 35/100 train_loss: 0.0020, valid_loss: 0.0055\n",
      "1.6694269180297852\n",
      "Epoch 36/100 train_loss: 0.0018, valid_loss: 0.0052\n",
      "1.6630854606628418\n",
      "Epoch 37/100 train_loss: 0.0016, valid_loss: 0.0049\n",
      "1.6453971862792969\n",
      "Epoch 38/100 train_loss: 0.0015, valid_loss: 0.0047\n",
      "1.6618633270263672\n",
      "Epoch 39/100 train_loss: 0.0014, valid_loss: 0.0045\n",
      "1.6595351696014404\n",
      "Epoch 40/100 train_loss: 0.0013, valid_loss: 0.0043\n",
      "1.6793136596679688\n",
      "Epoch 41/100 train_loss: 0.0012, valid_loss: 0.0042\n",
      "1.6772725582122803\n",
      "Epoch 42/100 train_loss: 0.0011, valid_loss: 0.0040\n",
      "1.6524381637573242\n",
      "Epoch 43/100 train_loss: 0.0010, valid_loss: 0.0038\n",
      "1.6711726188659668\n",
      "Epoch 44/100 train_loss: 0.0009, valid_loss: 0.0037\n",
      "1.6730682849884033\n",
      "Epoch 45/100 train_loss: 0.0009, valid_loss: 0.0035\n",
      "1.6682851314544678\n",
      "Epoch 46/100 train_loss: 0.0008, valid_loss: 0.0034\n",
      "1.6922495365142822\n",
      "Epoch 47/100 train_loss: 0.0008, valid_loss: 0.0033\n",
      "1.6861169338226318\n",
      "Epoch 48/100 train_loss: 0.0007, valid_loss: 0.0032\n",
      "1.661015272140503\n",
      "Epoch 49/100 train_loss: 0.0007, valid_loss: 0.0031\n",
      "1.674504280090332\n",
      "Epoch 50/100 train_loss: 0.0006, valid_loss: 0.0031\n",
      "1.6740267276763916\n",
      "Epoch 51/100 train_loss: 0.0006, valid_loss: 0.0030\n",
      "1.66617751121521\n",
      "Epoch 52/100 train_loss: 0.0006, valid_loss: 0.0030\n",
      "1.681074619293213\n",
      "Epoch 53/100 train_loss: 0.0005, valid_loss: 0.0030\n",
      "1.6913087368011475\n",
      "Epoch 54/100 train_loss: 0.0005, valid_loss: 0.0030\n",
      "1.6753957271575928\n",
      "Epoch 55/100 train_loss: 0.0005, valid_loss: 0.0030\n",
      "1.670743703842163\n",
      "Epoch 56/100 train_loss: 0.0004, valid_loss: 0.0031\n",
      "1.6755619049072266\n",
      "Epoch 57/100 train_loss: 0.0004, valid_loss: 0.0031\n",
      "1.6626911163330078\n",
      "Epoch 58/100 train_loss: 0.0004, valid_loss: 0.0032\n",
      "1.6484267711639404\n",
      "Epoch 59/100 train_loss: 0.0004, valid_loss: 0.0033\n",
      "1.6656770706176758\n",
      "Epoch 60/100 train_loss: 0.0003, valid_loss: 0.0034\n",
      "1.6529088020324707\n",
      "Epoch 61/100 train_loss: 0.0003, valid_loss: 0.0036\n",
      "1.6769232749938965\n",
      "Epoch 62/100 train_loss: 0.0003, valid_loss: 0.0037\n",
      "1.679823875427246\n",
      "Epoch 63/100 train_loss: 0.0003, valid_loss: 0.0038\n",
      "1.663823127746582\n",
      "Epoch 64/100 train_loss: 0.0003, valid_loss: 0.0039\n",
      "1.6640973091125488\n",
      "Epoch 65/100 train_loss: 0.0003, valid_loss: 0.0040\n",
      "1.6844737529754639\n",
      "Epoch 66/100 train_loss: 0.0002, valid_loss: 0.0041\n",
      "1.6771597862243652\n",
      "Epoch 67/100 train_loss: 0.0002, valid_loss: 0.0042\n",
      "1.7001805305480957\n",
      "Epoch 68/100 train_loss: 0.0002, valid_loss: 0.0043\n",
      "1.6880698204040527\n",
      "Epoch 69/100 train_loss: 0.0002, valid_loss: 0.0044\n",
      "1.6833713054656982\n",
      "Epoch 70/100 train_loss: 0.0002, valid_loss: 0.0045\n",
      "1.6745905876159668\n",
      "Epoch 71/100 train_loss: 0.0002, valid_loss: 0.0046\n",
      "1.6797194480895996\n",
      "Epoch 72/100 train_loss: 0.0002, valid_loss: 0.0047\n",
      "1.6829047203063965\n",
      "Epoch 73/100 train_loss: 0.0002, valid_loss: 0.0048\n",
      "1.6956923007965088\n",
      "Epoch 74/100 train_loss: 0.0002, valid_loss: 0.0049\n",
      "1.668381929397583\n",
      "Epoch 75/100 train_loss: 0.0002, valid_loss: 0.0049\n",
      "1.6826715469360352\n",
      "Epoch 76/100 train_loss: 0.0001, valid_loss: 0.0050\n",
      "1.6895391941070557\n",
      "Epoch 77/100 train_loss: 0.0001, valid_loss: 0.0050\n",
      "1.6609797477722168\n",
      "Epoch 78/100 train_loss: 0.0001, valid_loss: 0.0051\n",
      "1.6513025760650635\n",
      "Epoch 79/100 train_loss: 0.0001, valid_loss: 0.0051\n",
      "1.6648237705230713\n",
      "Epoch 80/100 train_loss: 0.0001, valid_loss: 0.0052\n",
      "1.6660950183868408\n",
      "Epoch 81/100 train_loss: 0.0001, valid_loss: 0.0053\n",
      "1.6655325889587402\n",
      "Epoch 82/100 train_loss: 0.0001, valid_loss: 0.0053\n",
      "1.6539192199707031\n",
      "Epoch 83/100 train_loss: 0.0001, valid_loss: 0.0053\n",
      "1.6711397171020508\n",
      "Epoch 84/100 train_loss: 0.0001, valid_loss: 0.0054\n",
      "1.6651580333709717\n",
      "Epoch 85/100 train_loss: 0.0001, valid_loss: 0.0054\n",
      "1.681530475616455\n",
      "Epoch 86/100 train_loss: 0.0001, valid_loss: 0.0055\n",
      "1.6826331615447998\n",
      "Epoch 87/100 train_loss: 0.0001, valid_loss: 0.0055\n",
      "1.6613245010375977\n",
      "Epoch 88/100 train_loss: 0.0001, valid_loss: 0.0056\n",
      "1.6682462692260742\n",
      "Epoch 89/100 train_loss: 0.0001, valid_loss: 0.0056\n",
      "1.6722700595855713\n",
      "Epoch 90/100 train_loss: 0.0001, valid_loss: 0.0057\n",
      "1.6839735507965088\n",
      "Epoch 91/100 train_loss: 0.0001, valid_loss: 0.0057\n",
      "1.6641571521759033\n",
      "Epoch 92/100 train_loss: 0.0001, valid_loss: 0.0058\n",
      "1.677037239074707\n",
      "Epoch 93/100 train_loss: 0.0001, valid_loss: 0.0058\n",
      "1.676884651184082\n",
      "Epoch 94/100 train_loss: 0.0001, valid_loss: 0.0059\n",
      "1.675948143005371\n",
      "Epoch 95/100 train_loss: 0.0001, valid_loss: 0.0059\n",
      "1.6705670356750488\n",
      "Epoch 96/100 train_loss: 0.0001, valid_loss: 0.0060\n",
      "1.6708972454071045\n",
      "Epoch 97/100 train_loss: 0.0001, valid_loss: 0.0060\n",
      "1.6715989112854004\n",
      "Epoch 98/100 train_loss: 0.0001, valid_loss: 0.0061\n",
      "1.6475396156311035\n",
      "Epoch 99/100 train_loss: 0.0000, valid_loss: 0.0061\n",
      "1.6587731838226318\n",
      "Epoch 100/100 train_loss: 0.0000, valid_loss: 0.0062\n",
      "1.662076473236084\n",
      "Model Trained\n"
     ]
    }
   ],
   "source": [
    "train_source = source_letter_ids[batch_size:]\n",
    "train_target = target_letter_ids[batch_size:]\n",
    "valid_source = source_letter_ids[:batch_size]\n",
    "valid_target = target_letter_ids[:batch_size]\n",
    "(valid_sources_batch, valid_targets_batch, valid_sources_lengths, valid_targets_lengths) = next(get_batches(valid_target, valid_source, batch_size,\n",
    "                           source_letter_to_int['<PAD>'],\n",
    "                           target_letter_to_int['<PAD>']))\n",
    "\n",
    "\n",
    "checkpoint = \"attention_model/best_model.ckpt\"\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    total_train_loss = []\n",
    "    total_valid_loss = []\n",
    "    total_batch = len(train_source) // batch_size\n",
    "    \n",
    "    for epoch_i in range(1, epochs+1):\n",
    "        \n",
    "        start = time.time()\n",
    "        train_loss = []\n",
    "        valid_loss = []\n",
    "        for batch_i, (sources_batch, targets_batch, sources_lengths, targets_lengths) in enumerate(\n",
    "                get_batches(train_target, train_source, batch_size,\n",
    "                           source_letter_to_int['<PAD>'],\n",
    "                           target_letter_to_int['<PAD>'])):\n",
    "            # Training step\n",
    "            _, loss_, train_attn = sess.run(\n",
    "                [seq2seq_attn.train_op, seq2seq_attn.loss,\n",
    "                 seq2seq_attn.train_attention_metrices],\n",
    "                {sources: sources_batch,\n",
    "                 targets: targets_batch,\n",
    "                 target_length: targets_lengths,\n",
    "                 source_length: sources_lengths})\n",
    "            \n",
    "            train_loss.append(loss_)\n",
    "            \n",
    "\n",
    "                \n",
    "        # Calculate validation cost\n",
    "        validation_loss = sess.run(seq2seq_attn.loss,{sources: valid_sources_batch,\n",
    "                                                      targets: valid_targets_batch,\n",
    "                                                      target_length: valid_targets_lengths,\n",
    "                                                      source_length: valid_sources_lengths})\n",
    "        valid_loss.append(validation_loss)\n",
    "        \n",
    "        train_loss = np.mean(train_loss)\n",
    "        \n",
    "        total_train_loss.append(train_loss)\n",
    "        total_valid_loss.append(valid_loss)\n",
    "        \n",
    "        print('Epoch %d/%d train_loss: %.4f, valid_loss: %.4f' % (epoch_i,epochs, train_loss, validation_loss))\n",
    "        print(time.time() - start)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, checkpoint)\n",
    "    print('Model Trained')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_to_seq(text):\n",
    "    '''Prepare the text for the model'''\n",
    "    sequence_length = 7\n",
    "    return [source_letter_to_int.get(word, source_letter_to_int['<UNK>']) for word in text]+ [source_letter_to_int['<PAD>']]*(sequence_length-len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/best_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "input_sentence = 'lexa'\n",
    "text = source_to_seq(input_sentence)\n",
    "\n",
    "checkpoint = \"model/best_model.ckpt\"\n",
    "\n",
    "loaded_graph = tf.Graph() # 建立靜態圖\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(checkpoint + '.meta') # 載入先前訓練好的模型靜態圖\n",
    "    loader.restore(sess, checkpoint) # 在sess中載入模型參數(weights, bias)\n",
    "\n",
    "    input_data = loaded_graph.get_tensor_by_name('sources:0') # 載入input placeholder\n",
    "    logits = loaded_graph.get_tensor_by_name('predictions:0') # 載入inference\n",
    "    source_sequence_length = loaded_graph.get_tensor_by_name('source_length:0')\n",
    "    target_sequence_length = loaded_graph.get_tensor_by_name('target_length:0')\n",
    "    \n",
    "    inference_attention_metrics = loaded_graph.get_tensor_by_name('decoder_1/inference_attention_metrices/inference_attention_metrices:0')\n",
    "    \n",
    "    #Multiply by batch_size to match the model's input parameters\n",
    "    answer_logits, att = sess.run([logits, inference_attention_metrics], {input_data: [text]*batch_size,\n",
    "                                      target_sequence_length: [len(input_sentence)]*batch_size,\n",
    "                                      source_sequence_length: [len(input_sentence)]*batch_size})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: lexa\n",
      "\n",
      "Source\n",
      "  Word Ids:    [15, 8, 27, 4, 0, 0, 0]\n",
      "  Input Words: l e x a <PAD> <PAD> <PAD>\n",
      "\n",
      "Target\n",
      "  Word Ids:       [4, 8, 15, 27]\n",
      "  Response Words: a e l x\n"
     ]
    }
   ],
   "source": [
    "pad = source_letter_to_int[\"<PAD>\"] \n",
    "\n",
    "print('Original Text:', input_sentence)\n",
    "\n",
    "print('\\nSource')\n",
    "print('  Word Ids:    {}'.format([i for i in text]))\n",
    "print('  Input Words: {}'.format(\" \".join([source_int_to_letter[i] for i in text])))\n",
    "\n",
    "print('\\nTarget')\n",
    "print('  Word Ids:       {}'.format([i for i in answer_logits if i != pad]))\n",
    "print('  Response Words: {}'.format(\" \".join([target_int_to_letter[i] for i in answer_logits if i != pad])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 128, 7)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att.shape # (output_len, batch_size, maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention map visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l</th>\n",
       "      <th>e</th>\n",
       "      <th>x</th>\n",
       "      <th>a</th>\n",
       "      <th>&lt;PAD&gt;</th>\n",
       "      <th>&lt;PAD&gt;</th>\n",
       "      <th>&lt;PAD&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>9.535641e-08</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.995453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>2.730971e-05</td>\n",
       "      <td>0.999895</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>9.999098e-01</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>7.102809e-05</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.998766</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              l         e         x         a  <PAD>  <PAD>  <PAD>\n",
       "a  9.535641e-08  0.000579  0.003968  0.995453    0.0    0.0    0.0\n",
       "e  2.730971e-05  0.999895  0.000001  0.000077    0.0    0.0    0.0\n",
       "l  9.999098e-01  0.000071  0.000008  0.000011    0.0    0.0    0.0\n",
       "x  7.102809e-05  0.000023  0.998766  0.001141    0.0    0.0    0.0"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_map = pd.DataFrame(att[:,0,:], \n",
    "                       columns=[source_int_to_letter.get(t) for t in text], \n",
    "                       index=[target_int_to_letter.get(t) for t in answer_logits[0]])\n",
    "att_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc559150048>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(att_map, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
